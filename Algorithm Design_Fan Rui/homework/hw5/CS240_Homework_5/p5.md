# hw5p5

Date: 5/17/2023, 8:33:54 PM
Model: Default
generated by [ChatGPT Web Share](https://github.com/moeakwak/chatgpt-web-share)

---

## 1. Suppose that for some decision problem, we have...

### User

Suppose that for some decision problem, we have an algorithm which on any instance computes the correct answer with probability at least 4/5. We wish to reduce the probability of error by running the algorithm $n$ times on the same input using independent randomness between trials and taking the most common result. Using Chernoff bounds, give an upper bound on the probability that this new algorithm produces an incorrect result.

### ChatGPT

To apply Chernoff bounds in this scenario, let's assume that our algorithm produces an incorrect result with probability \(p\). Since the algorithm computes the correct answer with probability at least \(4/5\) on any instance, we have \(p \leq 1/5\).

Let \(X\) be a random variable that represents the number of incorrect results obtained when running the algorithm \(n\) times. \(X\) follows a binomial distribution with parameters \(n\) and \(p\).

The probability of getting \(k\) incorrect results out of \(n\) trials is given by the binomial probability formula:

\[P(X = k) = \binom{n}{k} p^k (1 - p)^{n-k}\]

We want to find an upper bound on the probability that the new algorithm produces an incorrect result. This can be expressed as the probability that the number of incorrect results, \(X\), exceeds \(n/2\), since we are taking the most common result.

\[P(X > n/2) = P(X \geq \lceil n/2 \rceil) = P(X \geq \lceil 0.5n \rceil)\]

To apply Chernoff bounds, we need to find the expectation of \(X\), denoted as \(\mu\). For a binomial distribution, the expectation is given by:

\[\mu = np\]

Now, we can use Chernoff bounds to obtain an upper bound on \(P(X > n/2)\). Chernoff bounds provide exponential tail bounds for sums of independent random variables. In this case, we have \(n\) independent trials.

Using Chernoff bound with the parameter \(\delta > 0\), we have:

\[P(X \geq (1+\delta)\mu) \leq e^{-\frac{\delta^2 \mu}{3}}\]

In our case, we want to find an upper bound on \(P(X > n/2)\), so \((1+\delta)\mu\) corresponds to \(n/2\). Let's solve for \(\delta\):

\[(1+\delta)\mu = \frac{n}{2} \implies (1+\delta) = \frac{n}{2\mu} = \frac{2n}{np} = \frac{2}{p}\]

Substituting \(p = 1/5\), we get:

\[(1+\delta) = \frac{2}{1/5} = 10\]

Now we can use the Chernoff bound formula to obtain an upper bound on \(P(X > n/2)\):

\[P(X > n/2) \leq P(X \geq (1+\delta)\mu) \leq e^{-\frac{\delta^2 \mu}{3}} = e^{-\frac{10^2 \cdot np}{3}} = e^{-\frac{100n}{15}} = e^{-\frac{20n}{3}}\]

Therefore, the upper bound on the probability that the new algorithm produces an incorrect result is \(e^{-\frac{20n}{3}}\).

---

